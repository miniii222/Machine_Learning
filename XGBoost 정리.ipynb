{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "\n",
    "\n",
    "https://www.kaggle.com/lifesailor/xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Advantages\n",
    "## Regularization\n",
    "- Standard GBM은 regularization과정이 없다.\n",
    "- XGBoosts is also known as 'regularized boosting'\n",
    "## Parallel Processing\n",
    "- boosting은 sequential process인데 어떻게 병렬로?\n",
    "- 각 트리들은 이전 트리가 있어야만 생성되므로\n",
    "## High Flexibility\n",
    "- allow users to define custom optimization objectives and evaluation criteria\n",
    "## Handling Missing Values\n",
    "- have an in-built routine to handle missing values\n",
    "## Tree Pruning\n",
    "- GBM : stop splitting a node when it encounters a negative loss in the split(greedy algorithm)\n",
    "- XGBoost : splits upto the max_depth. start pruning the tree backwards and remove splits beyond which there is no positie gain\n",
    "## Built-in CV\n",
    "- run a cross-validation at each iteration\n",
    "## Continue on Existing Model\n",
    "- User can start training an XGBoost model from its last iteration of previous run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Parameter : Guide the overall functioning\n",
    "### booster[default = gbtree] \n",
    "- Select the type of model to run at each iteration\n",
    "    - gbtree : tree-based models\n",
    "    - gblinear : linear models\n",
    "    \n",
    "### silent[default = 0]\n",
    "- activated is set to 1. 실행중인 메시지 인쇄x\n",
    "\n",
    "### nthread[default : maximum number of threads]\n",
    "- 병렬 처리에 사용되는 코어 수 입력\n",
    "- 아무것도 안 하면(default) 는 최대"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Booster Parameters : Guide the individual booster at each step\n",
    "consider only tree booster\n",
    "\n",
    "### eta [default = 0.3]\n",
    "- learning rate\n",
    "### min_child_weight[default = 1]\n",
    "- child에 필요한 모든 관측치의 최소 가중치 합\n",
    "- GBM의 min_child_leaf와 유사하지만, 정확히는 아님. 관측치의 최소'가중치'\n",
    "- 오버피팅을 제어하는데 사용.\n",
    "- 값이 클수록 specific to the particular sample selected for a tree\n",
    "- too high -> under-fitting. it should be tuned using CV\n",
    "### max_depth [default = 6]\n",
    "- maximum depth of a tree\n",
    "- 오버피팅을 제어하는데 사용. higher depth -> learn relations very specific to a particular sample\n",
    "- should be tuned using CV\n",
    "- 3-10\n",
    "### max_leaf_nodes\n",
    "- 하나의 트리에서 node 개수\n",
    "- max_depth 대신 정의 가능\n",
    "### gamma[default = 0]\n",
    "- split할 때, 수행하는 데 필요한 최소 손실 감소 지정\n",
    "### max_delta_step [delata = 0]\n",
    "- 0이면, 제약 조건이 없음\n",
    "- 양수 값으로 설정하면, 보수적으로 설정\n",
    "### subsample [default=1]\n",
    "- 관측치의 비율을 각 트리의 무작위 샘플로\n",
    "- 값이 낮을수록 보수적.\n",
    "- 0.5-1\n",
    "### colsample_bytree [default=1]\n",
    "\n",
    "### lambda [default=1]\n",
    "- L2\n",
    "- 잘 안 씀\n",
    "### alpha [default=0]\n",
    "- L1\n",
    "### scale_pos_weight [default=1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Task Paramters : Guide the optimization performed\n",
    "### objective [default = reg:linear]\n",
    "- binary:logistic(이진 분류)\n",
    "- multi:softmax(다중 분류)\n",
    "- multi:softprob(다중 확률)\n",
    "### eval_metric[default according to objective]\n",
    "- rmse\n",
    "- mae\n",
    "- logloss\n",
    "- error\n",
    "- merror\n",
    "- mlogloss\n",
    "- auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Approach for Paramter tuning\n",
    "## Choose a relatively high learning rate & optimum number of trees for this learning rate\n",
    "- 0.05 - 0.3\n",
    "- 'cv'를 이용하면, 각 boosting 반복마다 최적 수의 트리 반환\n",
    "\n",
    "## Tune tree-specific parmeters\n",
    "- max_depth, min_child_weight, gamma, subsample, colsample_bytree \n",
    "\n",
    "## regularization parameters\n",
    "- lambda, alpha\n",
    "\n",
    "## lower the learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice using titanic data\n",
    "- 여기서는 자세한 전처리 x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T10:54:00.723503Z",
     "start_time": "2019-03-18T10:54:00.712528Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12,4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gender_submission.csv', 'train.csv', 'test.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('./titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T10:04:37.550640Z",
     "start_time": "2019-03-18T10:04:37.524336Z"
    }
   },
   "outputs": [],
   "source": [
    "path = './titanic/'\n",
    "\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T10:04:50.665842Z",
     "start_time": "2019-03-18T10:04:50.620764Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass    ...        Fare Cabin  Embarked\n",
       "0            1         0       3    ...      7.2500   NaN         S\n",
       "1            2         1       1    ...     71.2833   C85         C\n",
       "2            3         1       3    ...      7.9250   NaN         S\n",
       "3            4         1       1    ...     53.1000  C123         S\n",
       "4            5         0       3    ...      8.0500   NaN         S\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T10:04:56.363321Z",
     "start_time": "2019-03-18T10:04:56.348501Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T10:05:36.863897Z",
     "start_time": "2019-03-18T10:05:36.855076Z"
    }
   },
   "outputs": [],
   "source": [
    "# 처리하기 힘든 columns 제거\n",
    "del train['Ticket']; del test['Ticket']\n",
    "del train['Cabin']; del test['Cabin']\n",
    "del train['Name']; del test['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T10:07:14.285812Z",
     "start_time": "2019-03-18T10:07:14.275168Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch',\n",
       "       'Fare', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T10:08:08.312730Z",
     "start_time": "2019-03-18T10:08:08.299699Z"
    }
   },
   "outputs": [],
   "source": [
    "#test에 예측값인 Survived 추가해서 합침\n",
    "test.insert(loc = 1, column = 'Survived', value = 0)\n",
    "total = pd.concat([train, test], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T10:08:17.413188Z",
     "start_time": "2019-03-18T10:08:17.405095Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1309, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T10:10:00.713243Z",
     "start_time": "2019-03-18T10:10:00.699940Z"
    }
   },
   "outputs": [],
   "source": [
    "#One hot encoding\n",
    "sex = pd.get_dummies(total.Sex)\n",
    "embarked = pd.get_dummies(total.Embarked)\n",
    "\n",
    "#기존 칼럼 제거\n",
    "del total['Sex']\n",
    "del total['Embarked']\n",
    "\n",
    "#One hot 한거 다시 합치기\n",
    "total = pd.concat([total, sex, embarked], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T10:10:17.187992Z",
     "start_time": "2019-03-18T10:10:17.163721Z"
    }
   },
   "outputs": [],
   "source": [
    "total[\"Family\"] = total[\"Parch\"] + total[\"SibSp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T10:10:49.621195Z",
     "start_time": "2019-03-18T10:10:49.610750Z"
    }
   },
   "outputs": [],
   "source": [
    "train = total[:len(train)]\n",
    "test = total[len(train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T10:10:56.465855Z",
     "start_time": "2019-03-18T10:10:56.435788Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass   Age  SibSp  Parch     Fare  female  male  \\\n",
       "0            1         0       3  22.0      1      0   7.2500       0     1   \n",
       "1            2         1       1  38.0      1      0  71.2833       1     0   \n",
       "2            3         1       3  26.0      0      0   7.9250       1     0   \n",
       "3            4         1       1  35.0      1      0  53.1000       1     0   \n",
       "4            5         0       3  35.0      0      0   8.0500       0     1   \n",
       "\n",
       "   C  Q  S  Family  \n",
       "0  0  0  1       1  \n",
       "1  1  0  0       1  \n",
       "2  0  0  1       0  \n",
       "3  0  0  1       1  \n",
       "4  0  0  1       0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T10:11:55.856513Z",
     "start_time": "2019-03-18T10:11:55.852971Z"
    }
   },
   "outputs": [],
   "source": [
    "target = 'Survived'\n",
    "IDcol = 'PassengerId'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T10:54:35.839739Z",
     "start_time": "2019-03-18T10:54:35.824459Z"
    }
   },
   "outputs": [],
   "source": [
    "def modelfit(algo, dtrain, predictors, useTrainCV = True, cv_folds = 5, early_stopping_rounds = 100) :\n",
    "    \n",
    "    if useTrainCV :\n",
    "        xgb_param = algo.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label = dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round = algo.get_xgb_params()['n_estimators'], nfold = cv_folds,\n",
    "                    metrics = 'error', early_stopping_rounds = early_stopping_rounds)\n",
    "        algo.set_params(n_estimators = cvresult.shape[0])\n",
    "        print(algo)\n",
    "        \n",
    "    algo.fit(dtrain[predictors], dtrain['Survived'], eval_metric = 'error')\n",
    "    \n",
    "    dtrain_predictions = algo.predict(dtrain[predictors])\n",
    "    dtrain_predprob = algo.predict_proba(dtrain[predictors])[:,1] #predict probability\n",
    "    \n",
    "    print('\\nModel Report')\n",
    "    print('Training Accuracy : %.4g' %metrics.accuracy_score(dtrain['Survived'].values, dtrain_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learing rate, estimator\n",
    "- max_depth = 5 : 보통 4-6\n",
    "- min_child_weight = 1 : 향후에 튜닝할 것\n",
    "- gamma = 9 : 0.1 - 0.2 나중에 튜닝\n",
    "- subsample, colsample_bytree = 0.8 : 보통 0.5-0.9\n",
    "- scale_pos_weight = 1 : because of high class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T10:55:50.741188Z",
     "start_time": "2019-03-18T10:55:49.264790Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=5, min_child_weight=1, missing=None, n_estimators=178,\n",
      "       n_jobs=1, nthread=-1, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=2019,\n",
      "       silent=True, subsample=0.8)\n",
      "\n",
      "Model Report\n",
      "Training Accuracy : 0.9405\n"
     ]
    }
   ],
   "source": [
    "predictors = [x for x in train.columns if x not in [target, IDcol]]\n",
    "\n",
    "xgb1 = XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=5,\n",
    "    min_child_weight=1,\n",
    "    gamma = 0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=-1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=2019\n",
    ")\n",
    "\n",
    "modelfit(xgb1, train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T11:03:36.859353Z",
     "start_time": "2019-03-18T11:03:24.912432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  45 | elapsed:    4.7s remaining:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  45 | elapsed:    5.0s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    5.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    5.4s finished\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([0.84293032, 0.74992938, 0.51704259, 0.73263183, 0.68282795,\n",
       "         0.62738881, 0.82155585, 0.75793433, 0.58821659]),\n",
       "  'mean_score_time': array([0.00770764, 0.00780239, 0.00731893, 0.01220026, 0.01102514,\n",
       "         0.00910645, 0.01250825, 0.0103817 , 0.00740929]),\n",
       "  'mean_test_score': array([0.8182518 , 0.8294879 , 0.84292076, 0.81147856, 0.81820772,\n",
       "         0.83283993, 0.80361325, 0.81709675, 0.83395717]),\n",
       "  'mean_train_score': array([0.96577285, 0.94781422, 0.93434368, 0.98344665, 0.97250576,\n",
       "         0.95314303, 0.98372755, 0.97278627, 0.95370483]),\n",
       "  'param_max_depth': masked_array(data=[3, 3, 3, 6, 6, 6, 9, 9, 9],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_min_child_weight': masked_array(data=[1, 3, 5, 1, 3, 5, 1, 3, 5],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'max_depth': 3, 'min_child_weight': 1},\n",
       "   {'max_depth': 3, 'min_child_weight': 3},\n",
       "   {'max_depth': 3, 'min_child_weight': 5},\n",
       "   {'max_depth': 6, 'min_child_weight': 1},\n",
       "   {'max_depth': 6, 'min_child_weight': 3},\n",
       "   {'max_depth': 6, 'min_child_weight': 5},\n",
       "   {'max_depth': 9, 'min_child_weight': 1},\n",
       "   {'max_depth': 9, 'min_child_weight': 3},\n",
       "   {'max_depth': 9, 'min_child_weight': 5}],\n",
       "  'rank_test_score': array([5, 4, 1, 8, 6, 3, 9, 7, 2], dtype=int32),\n",
       "  'split0_test_score': array([0.7877095 , 0.80446927, 0.83240223, 0.78212291, 0.80446927,\n",
       "         0.81564246, 0.78212291, 0.80446927, 0.82681564]),\n",
       "  'split0_train_score': array([0.96348315, 0.94803371, 0.93117978, 0.98174157, 0.97191011,\n",
       "         0.9508427 , 0.98314607, 0.97331461, 0.95224719]),\n",
       "  'split1_test_score': array([0.81564246, 0.81005587, 0.82122905, 0.82681564, 0.82681564,\n",
       "         0.82122905, 0.81564246, 0.82122905, 0.81005587]),\n",
       "  'split1_train_score': array([0.97331461, 0.95365169, 0.93679775, 0.98735955, 0.9761236 ,\n",
       "         0.95505618, 0.98735955, 0.9747191 , 0.95646067]),\n",
       "  'split2_test_score': array([0.86516854, 0.86516854, 0.87640449, 0.85393258, 0.83707865,\n",
       "         0.85955056, 0.8258427 , 0.83707865, 0.85393258]),\n",
       "  'split2_train_score': array([0.97194951, 0.94810659, 0.93969144, 0.98316971, 0.97615708,\n",
       "         0.95652174, 0.98316971, 0.97615708, 0.95652174]),\n",
       "  'split3_test_score': array([0.7752809 , 0.80898876, 0.83146067, 0.76966292, 0.78651685,\n",
       "         0.80337079, 0.78089888, 0.78089888, 0.82022472]),\n",
       "  'split3_train_score': array([0.96353436, 0.94530154, 0.9312763 , 0.98316971, 0.97335203,\n",
       "         0.95231417, 0.98316971, 0.97475456, 0.95231417]),\n",
       "  'split4_test_score': array([0.84745763, 0.85875706, 0.85310734, 0.82485876, 0.83615819,\n",
       "         0.86440678, 0.81355932, 0.84180791, 0.85875706]),\n",
       "  'split4_train_score': array([0.95658263, 0.94397759, 0.93277311, 0.98179272, 0.96498599,\n",
       "         0.95098039, 0.98179272, 0.96498599, 0.95098039]),\n",
       "  'std_fit_time': array([0.11477835, 0.18628106, 0.00861503, 0.01702942, 0.02258559,\n",
       "         0.00800468, 0.02433075, 0.08094634, 0.03350989]),\n",
       "  'std_score_time': array([2.79000612e-04, 5.39774726e-04, 7.41616540e-05, 4.77531776e-04,\n",
       "         8.28757678e-04, 1.27252767e-04, 4.97855778e-04, 1.21103248e-03,\n",
       "         7.29746225e-04]),\n",
       "  'std_test_score': array([0.03417689, 0.02665911, 0.01968467, 0.03107057, 0.01972554,\n",
       "         0.02453129, 0.01852324, 0.02234606, 0.01910448]),\n",
       "  'std_train_score': array([0.00616024, 0.00332394, 0.00336175, 0.0020546 , 0.00409973,\n",
       "         0.00226854, 0.00189185, 0.00400239, 0.00232426])},\n",
       " {'max_depth': 3, 'min_child_weight': 5},\n",
       " 0.8429207596176591)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    "    'max_depth' : range(3,10,3),\n",
    "    'min_child_weight' : range(1,6,2)\n",
    "}\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier(learning_rate = 0.1,\n",
    "                                                  n_estimators=1000,\n",
    "                                                  max_depth=5,\n",
    "                                                  min_child_weight = 1,\n",
    "                                                  gamma = 0,\n",
    "                                                  subsample = 0.8,\n",
    "                                                  colsample_bytree = 0.8,\n",
    "                                                  objective= 'binary:logistic',\n",
    "                                                  nthread=-1,\n",
    "                                                  scale_pos_weight=1,\n",
    "                                                  seed=2019),\n",
    "        param_grid=param_test1, scoring = 'accuracy', n_jobs = -1, iid = False, cv = 5, verbose = 10)\n",
    "\n",
    "gsearch1.fit(train[predictors], train[target])\n",
    "gsearch1.cv_results_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.1, 0.2, 0.3, 0.4]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test2 = {\n",
    "    'gamma' : [i/10 for i in range(0,5)]\n",
    "}\n",
    "param_test2['gamma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([0.61900434, 0.57575178, 0.53889151, 0.53299499, 0.476548  ]),\n",
       "  'mean_score_time': array([0.00766706, 0.00759559, 0.0075964 , 0.00803833, 0.00711441]),\n",
       "  'mean_test_score': array([0.84292076, 0.84067357, 0.84068612, 0.8395499 , 0.84178447]),\n",
       "  'mean_train_score': array([0.93434368, 0.93462497, 0.93097722, 0.93097761, 0.92676846]),\n",
       "  'param_gamma': masked_array(data=[0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "               mask=[False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'gamma': 0.0},\n",
       "   {'gamma': 0.1},\n",
       "   {'gamma': 0.2},\n",
       "   {'gamma': 0.3},\n",
       "   {'gamma': 0.4}],\n",
       "  'rank_test_score': array([1, 4, 3, 5, 2], dtype=int32),\n",
       "  'split0_test_score': array([0.83240223, 0.83798883, 0.82681564, 0.83240223, 0.84357542]),\n",
       "  'split0_train_score': array([0.93117978, 0.93258427, 0.92837079, 0.93117978, 0.92275281]),\n",
       "  'split1_test_score': array([0.82122905, 0.81564246, 0.81564246, 0.81564246, 0.81005587]),\n",
       "  'split1_train_score': array([0.93679775, 0.93679775, 0.93398876, 0.93398876, 0.93258427]),\n",
       "  'split2_test_score': array([0.87640449, 0.86516854, 0.87078652, 0.86516854, 0.87640449]),\n",
       "  'split2_train_score': array([0.93969144, 0.93969144, 0.9312763 , 0.93267882, 0.9256662 ]),\n",
       "  'split3_test_score': array([0.83146067, 0.83146067, 0.83707865, 0.83707865, 0.83707865]),\n",
       "  'split3_train_score': array([0.9312763 , 0.93267882, 0.93267882, 0.92706872, 0.92706872]),\n",
       "  'split4_test_score': array([0.85310734, 0.85310734, 0.85310734, 0.84745763, 0.84180791]),\n",
       "  'split4_train_score': array([0.93277311, 0.93137255, 0.92857143, 0.92997199, 0.92577031]),\n",
       "  'std_fit_time': array([0.01633255, 0.03639635, 0.00998349, 0.00155489, 0.11392868]),\n",
       "  'std_score_time': array([0.00035663, 0.00021402, 0.00020304, 0.00129155, 0.00100736]),\n",
       "  'std_test_score': array([0.01968467, 0.01716534, 0.01945718, 0.01641712, 0.02112157]),\n",
       "  'std_train_score': array([0.00336175, 0.00312795, 0.00221971, 0.00237877, 0.00323266])},\n",
       " {'gamma': 0.0},\n",
       " 0.8429207596176591)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch2 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, \n",
    "                                                  n_estimators=1000, \n",
    "                                                  max_depth=3,\n",
    "                                                  min_child_weight=5, \n",
    "                                                  gamma=0, \n",
    "                                                  subsample=0.8, \n",
    "                                                  colsample_bytree=0.8,\n",
    "                                                  objective= 'binary:logistic', \n",
    "                                                  thread=-1, \n",
    "                                                  scale_pos_weight=1,\n",
    "                                                  seed=2019), \n",
    "                        param_grid = param_test2, scoring='accuracy', n_jobs=-1, iid=False, cv=5)\n",
    "gsearch2.fit(train[predictors],train[target])\n",
    "gsearch2.cv_results_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  74 out of  80 | elapsed:    5.7s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    5.9s finished\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([0.60735598, 0.585116  , 0.51571569, 0.51966867, 0.53691659,\n",
       "         0.52016096, 0.51768885, 0.51958051, 0.52128882, 0.53322258,\n",
       "         0.52088256, 0.50818386, 0.54736056, 0.54200907, 0.51588144,\n",
       "         0.49803333]),\n",
       "  'mean_score_time': array([0.00756731, 0.00754328, 0.00763516, 0.00742121, 0.00757761,\n",
       "         0.007478  , 0.00746498, 0.0073431 , 0.00742784, 0.00732594,\n",
       "         0.00771322, 0.00727406, 0.00746398, 0.00753517, 0.00751123,\n",
       "         0.00574565]),\n",
       "  'mean_test_score': array([0.83951189, 0.84287654, 0.84179709, 0.83841996, 0.84288916,\n",
       "         0.83730257, 0.84177812, 0.83841996, 0.84514898, 0.84177191,\n",
       "         0.84292076, 0.83729636, 0.84288274, 0.83726491, 0.83951837,\n",
       "         0.83168466]),\n",
       "  'mean_train_score': array([0.9163878 , 0.92059616, 0.92424116, 0.92620824, 0.91947257,\n",
       "         0.92536397, 0.92873357, 0.93181873, 0.92480296, 0.92873043,\n",
       "         0.93434368, 0.93434446, 0.92508267, 0.93209964, 0.93518558,\n",
       "         0.93827232]),\n",
       "  'param_colsample_bytree': masked_array(data=[0.6, 0.6, 0.6, 0.6, 0.7, 0.7, 0.7, 0.7, 0.8, 0.8, 0.8,\n",
       "                     0.8, 0.9, 0.9, 0.9, 0.9],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_subsample': masked_array(data=[0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8,\n",
       "                     0.9, 0.6, 0.7, 0.8, 0.9],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'colsample_bytree': 0.6, 'subsample': 0.6},\n",
       "   {'colsample_bytree': 0.6, 'subsample': 0.7},\n",
       "   {'colsample_bytree': 0.6, 'subsample': 0.8},\n",
       "   {'colsample_bytree': 0.6, 'subsample': 0.9},\n",
       "   {'colsample_bytree': 0.7, 'subsample': 0.6},\n",
       "   {'colsample_bytree': 0.7, 'subsample': 0.7},\n",
       "   {'colsample_bytree': 0.7, 'subsample': 0.8},\n",
       "   {'colsample_bytree': 0.7, 'subsample': 0.9},\n",
       "   {'colsample_bytree': 0.8, 'subsample': 0.6},\n",
       "   {'colsample_bytree': 0.8, 'subsample': 0.7},\n",
       "   {'colsample_bytree': 0.8, 'subsample': 0.8},\n",
       "   {'colsample_bytree': 0.8, 'subsample': 0.9},\n",
       "   {'colsample_bytree': 0.9, 'subsample': 0.6},\n",
       "   {'colsample_bytree': 0.9, 'subsample': 0.7},\n",
       "   {'colsample_bytree': 0.9, 'subsample': 0.8},\n",
       "   {'colsample_bytree': 0.9, 'subsample': 0.9}],\n",
       "  'rank_test_score': array([10,  5,  6, 11,  3, 13,  7, 11,  1,  8,  2, 14,  4, 15,  9, 16],\n",
       "        dtype=int32),\n",
       "  'split0_test_score': array([0.83240223, 0.84357542, 0.83240223, 0.83240223, 0.84357542,\n",
       "         0.81005587, 0.83240223, 0.82681564, 0.83798883, 0.84357542,\n",
       "         0.83240223, 0.82681564, 0.83798883, 0.83798883, 0.83798883,\n",
       "         0.82681564]),\n",
       "  'split0_train_score': array([0.91432584, 0.91573034, 0.91573034, 0.92134831, 0.91432584,\n",
       "         0.91853933, 0.92696629, 0.92977528, 0.91853933, 0.92275281,\n",
       "         0.93117978, 0.93258427, 0.91713483, 0.92837079, 0.93117978,\n",
       "         0.93539326]),\n",
       "  'split1_test_score': array([0.82122905, 0.82681564, 0.81564246, 0.81564246, 0.82122905,\n",
       "         0.82681564, 0.82122905, 0.82122905, 0.82122905, 0.82122905,\n",
       "         0.82122905, 0.82122905, 0.82122905, 0.83240223, 0.82681564,\n",
       "         0.81564246]),\n",
       "  'split1_train_score': array([0.92134831, 0.9255618 , 0.92837079, 0.93539326, 0.92275281,\n",
       "         0.92977528, 0.93258427, 0.93258427, 0.92977528, 0.93398876,\n",
       "         0.93679775, 0.93679775, 0.92837079, 0.93960674, 0.93820225,\n",
       "         0.93820225]),\n",
       "  'split2_test_score': array([0.88764045, 0.87078652, 0.87078652, 0.87640449, 0.87078652,\n",
       "         0.87078652, 0.87640449, 0.87078652, 0.87078652, 0.87640449,\n",
       "         0.87640449, 0.86516854, 0.87078652, 0.84831461, 0.86516854,\n",
       "         0.85955056]),\n",
       "  'split2_train_score': array([0.914446  , 0.92286115, 0.92426367, 0.92286115, 0.91865358,\n",
       "         0.92706872, 0.92847125, 0.93548387, 0.92706872, 0.9256662 ,\n",
       "         0.93969144, 0.9368864 , 0.92706872, 0.93267882, 0.93969144,\n",
       "         0.94389902]),\n",
       "  'split3_test_score': array([0.83707865, 0.84269663, 0.84269663, 0.8258427 , 0.84269663,\n",
       "         0.84269663, 0.84269663, 0.83146067, 0.85393258, 0.8258427 ,\n",
       "         0.83146067, 0.83146067, 0.85955056, 0.83146067, 0.83146067,\n",
       "         0.81460674]),\n",
       "  'split3_train_score': array([0.91865358, 0.92286115, 0.92847125, 0.92706872, 0.92426367,\n",
       "         0.9256662 , 0.9312763 , 0.93267882, 0.92286115, 0.92847125,\n",
       "         0.9312763 , 0.93408135, 0.92706872, 0.92706872, 0.93408135,\n",
       "         0.94109397]),\n",
       "  'split4_test_score': array([0.81920904, 0.83050847, 0.84745763, 0.84180791, 0.83615819,\n",
       "         0.83615819, 0.83615819, 0.84180791, 0.84180791, 0.84180791,\n",
       "         0.85310734, 0.84180791, 0.82485876, 0.83615819, 0.83615819,\n",
       "         0.84180791]),\n",
       "  'split4_train_score': array([0.91316527, 0.91596639, 0.92436975, 0.92436975, 0.91736695,\n",
       "         0.92577031, 0.92436975, 0.92857143, 0.92577031, 0.93277311,\n",
       "         0.93277311, 0.93137255, 0.92577031, 0.93277311, 0.93277311,\n",
       "         0.93277311]),\n",
       "  'std_fit_time': array([0.01111637, 0.06505779, 0.00779797, 0.03433476, 0.02290517,\n",
       "         0.00339705, 0.001365  , 0.01403571, 0.00227714, 0.01409425,\n",
       "         0.007347  , 0.01044452, 0.01269038, 0.00781566, 0.00411848,\n",
       "         0.04226291]),\n",
       "  'std_score_time': array([0.00023798, 0.00026443, 0.00028758, 0.00018856, 0.00050804,\n",
       "         0.0001127 , 0.00017588, 0.00034606, 0.00016855, 0.00012039,\n",
       "         0.00030465, 0.00019897, 0.00026107, 0.00030759, 0.00020628,\n",
       "         0.00072576]),\n",
       "  'std_test_score': array([0.02497717, 0.0154299 , 0.01814148, 0.02082075, 0.01608252,\n",
       "         0.02001968, 0.01866325, 0.01753677, 0.01654708, 0.01938256,\n",
       "         0.01968467, 0.01548723, 0.01936044, 0.00601963, 0.01340035,\n",
       "         0.01703939]),\n",
       "  'std_train_score': array([0.00310314, 0.00400072, 0.00463462, 0.00496602, 0.00361408,\n",
       "         0.00372016, 0.00295054, 0.00242816, 0.0038418 , 0.00422332,\n",
       "         0.00336175, 0.00221268, 0.00405812, 0.00438999, 0.00324003,\n",
       "         0.00395365])},\n",
       " {'colsample_bytree': 0.8, 'subsample': 0.6},\n",
       " 0.8451489775646174)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test3 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, \n",
    "                                                  n_estimators=1000, \n",
    "                                                  max_depth=3,\n",
    "                                                  min_child_weight=5, \n",
    "                                                  gamma=0, \n",
    "                                                  subsample=0.8, \n",
    "                                                  colsample_bytree=0.8,\n",
    "                                                  objective= 'binary:logistic', \n",
    "                                                  thread=-1, \n",
    "                                                  scale_pos_weight=1,\n",
    "                                                  seed=2019), \n",
    "                        param_grid = param_test3, scoring='accuracy', n_jobs=-1, iid=False, cv=5, verbose=10)\n",
    "gsearch3.fit(train[predictors],train[target])\n",
    "gsearch3.cv_results_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subsmple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   14.4s finished\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([0.52663989, 0.54592228, 0.53300538, 0.51812186, 0.53084121,\n",
       "         0.52108588, 0.52377338, 0.52543802, 0.51764407, 0.52498813,\n",
       "         0.52609825, 0.52710471, 0.52293944, 0.5204845 , 0.5137219 ,\n",
       "         0.53041739, 0.52431474, 0.52187872, 0.52965169, 0.51892619,\n",
       "         0.54811273, 0.51327   , 0.52449827, 0.53194833, 0.51064906,\n",
       "         0.51682243, 0.51874514, 0.50825253, 0.52831097, 0.53119144,\n",
       "         0.51170964, 0.52105465, 0.51728716, 0.51327381, 0.51864862,\n",
       "         0.52008214, 0.51348438, 0.51171517, 0.51946468, 0.41826086]),\n",
       "  'mean_score_time': array([0.00901346, 0.00735865, 0.00731416, 0.00729771, 0.00739918,\n",
       "         0.00726089, 0.00738935, 0.00744252, 0.00726428, 0.00737419,\n",
       "         0.00736785, 0.00737462, 0.00728421, 0.00748019, 0.0073184 ,\n",
       "         0.00734296, 0.00738125, 0.00734944, 0.00741096, 0.00739679,\n",
       "         0.00738177, 0.00731111, 0.00786686, 0.00735931, 0.00734172,\n",
       "         0.00732851, 0.00740452, 0.00727415, 0.00736594, 0.00741944,\n",
       "         0.0073247 , 0.0073041 , 0.00742164, 0.007442  , 0.00739245,\n",
       "         0.00732837, 0.00753078, 0.00724039, 0.00733719, 0.00586686]),\n",
       "  'mean_test_score': array([0.83610337, 0.83052312, 0.83838215, 0.83949298, 0.83611592,\n",
       "         0.83723951, 0.84173397, 0.8440002 , 0.84175915, 0.84398751,\n",
       "         0.84287019, 0.84509848, 0.83838843, 0.83838201, 0.84400634,\n",
       "         0.84061665, 0.83839464, 0.84067343, 0.83839464, 0.83613475,\n",
       "         0.84514898, 0.83951823, 0.84065445, 0.84401903, 0.8417655 ,\n",
       "         0.84513008, 0.83839471, 0.8496246 , 0.84174039, 0.84288288,\n",
       "         0.84177191, 0.84178447, 0.83952458, 0.84514277, 0.83954355,\n",
       "         0.84626637, 0.84178447, 0.83393171, 0.83728367, 0.84179075]),\n",
       "  'mean_train_score': array([0.90347551, 0.90627939, 0.90936888, 0.90993068, 0.90824371,\n",
       "         0.90824528, 0.91245758, 0.91161567, 0.91161252, 0.91553999,\n",
       "         0.91722499, 0.91638269, 0.91694684, 0.91806887, 0.9183474 ,\n",
       "         0.91778639, 0.9200328 , 0.92087313, 0.91975387, 0.92199672,\n",
       "         0.92480296, 0.92171504, 0.92143532, 0.92395987, 0.92368094,\n",
       "         0.9295747 , 0.92480296, 0.92676453, 0.92788734, 0.92732947,\n",
       "         0.92873043, 0.93013492, 0.93181716, 0.93013649, 0.93126009,\n",
       "         0.92873318, 0.93209806, 0.93238132, 0.93210082, 0.93125694]),\n",
       "  'param_subsample': masked_array(data=[0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48,\n",
       "                     0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57,\n",
       "                     0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66,\n",
       "                     0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75,\n",
       "                     0.76, 0.77, 0.78, 0.79],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'subsample': 0.4},\n",
       "   {'subsample': 0.41},\n",
       "   {'subsample': 0.42},\n",
       "   {'subsample': 0.43},\n",
       "   {'subsample': 0.44},\n",
       "   {'subsample': 0.45},\n",
       "   {'subsample': 0.46},\n",
       "   {'subsample': 0.47},\n",
       "   {'subsample': 0.48},\n",
       "   {'subsample': 0.49},\n",
       "   {'subsample': 0.5},\n",
       "   {'subsample': 0.51},\n",
       "   {'subsample': 0.52},\n",
       "   {'subsample': 0.53},\n",
       "   {'subsample': 0.54},\n",
       "   {'subsample': 0.55},\n",
       "   {'subsample': 0.56},\n",
       "   {'subsample': 0.57},\n",
       "   {'subsample': 0.58},\n",
       "   {'subsample': 0.59},\n",
       "   {'subsample': 0.6},\n",
       "   {'subsample': 0.61},\n",
       "   {'subsample': 0.62},\n",
       "   {'subsample': 0.63},\n",
       "   {'subsample': 0.64},\n",
       "   {'subsample': 0.65},\n",
       "   {'subsample': 0.66},\n",
       "   {'subsample': 0.67},\n",
       "   {'subsample': 0.68},\n",
       "   {'subsample': 0.69},\n",
       "   {'subsample': 0.7},\n",
       "   {'subsample': 0.71},\n",
       "   {'subsample': 0.72},\n",
       "   {'subsample': 0.73},\n",
       "   {'subsample': 0.74},\n",
       "   {'subsample': 0.75},\n",
       "   {'subsample': 0.76},\n",
       "   {'subsample': 0.77},\n",
       "   {'subsample': 0.78},\n",
       "   {'subsample': 0.79}],\n",
       "  'rank_test_score': array([38, 40, 32, 27, 37, 35, 20,  9, 18, 10, 12,  6, 31, 33,  8, 23, 29,\n",
       "         21, 29, 36,  3, 26, 22,  7, 17,  5, 28,  1, 19, 11, 16, 14, 25,  4,\n",
       "         24,  2, 14, 39, 34, 13], dtype=int32),\n",
       "  'split0_test_score': array([0.8547486 , 0.83240223, 0.84916201, 0.84357542, 0.83798883,\n",
       "         0.84916201, 0.84916201, 0.8603352 , 0.83240223, 0.83798883,\n",
       "         0.84357542, 0.84357542, 0.83798883, 0.83240223, 0.83240223,\n",
       "         0.83798883, 0.84357542, 0.82122905, 0.82122905, 0.83240223,\n",
       "         0.83798883, 0.82122905, 0.82122905, 0.83240223, 0.83240223,\n",
       "         0.84357542, 0.82681564, 0.84357542, 0.84357542, 0.83798883,\n",
       "         0.84357542, 0.83240223, 0.83240223, 0.83240223, 0.82122905,\n",
       "         0.84357542, 0.83240223, 0.81564246, 0.82122905, 0.83798883]),\n",
       "  'split0_train_score': array([0.89747191, 0.9002809 , 0.90308989, 0.90589888, 0.89606742,\n",
       "         0.90168539, 0.90730337, 0.90730337, 0.90449438, 0.90870787,\n",
       "         0.90730337, 0.90589888, 0.91011236, 0.91292135, 0.90870787,\n",
       "         0.91292135, 0.90870787, 0.91292135, 0.91853933, 0.91994382,\n",
       "         0.91853933, 0.91573034, 0.91994382, 0.92134831, 0.92134831,\n",
       "         0.92977528, 0.91994382, 0.91994382, 0.92275281, 0.92696629,\n",
       "         0.92275281, 0.92696629, 0.92696629, 0.92837079, 0.93398876,\n",
       "         0.9241573 , 0.92696629, 0.93117978, 0.92977528, 0.92275281]),\n",
       "  'split1_test_score': array([0.82681564, 0.82122905, 0.82122905, 0.82122905, 0.83240223,\n",
       "         0.82122905, 0.82681564, 0.81564246, 0.82681564, 0.83798883,\n",
       "         0.82681564, 0.83798883, 0.82681564, 0.82681564, 0.82681564,\n",
       "         0.83240223, 0.81005587, 0.82122905, 0.83240223, 0.82122905,\n",
       "         0.82122905, 0.83240223, 0.82681564, 0.82681564, 0.82681564,\n",
       "         0.82681564, 0.83240223, 0.83798883, 0.83798883, 0.83240223,\n",
       "         0.82122905, 0.82122905, 0.82122905, 0.83798883, 0.82681564,\n",
       "         0.82681564, 0.82122905, 0.81564246, 0.82681564, 0.81005587]),\n",
       "  'split1_train_score': array([0.90308989, 0.90589888, 0.91432584, 0.91432584, 0.91011236,\n",
       "         0.91011236, 0.91713483, 0.91853933, 0.91151685, 0.91573034,\n",
       "         0.92275281, 0.91994382, 0.92275281, 0.9241573 , 0.92275281,\n",
       "         0.91853933, 0.92977528, 0.9241573 , 0.9255618 , 0.92134831,\n",
       "         0.92977528, 0.9241573 , 0.92275281, 0.9241573 , 0.9255618 ,\n",
       "         0.93258427, 0.92977528, 0.92837079, 0.93117978, 0.92837079,\n",
       "         0.93398876, 0.93539326, 0.93398876, 0.93679775, 0.93820225,\n",
       "         0.93539326, 0.93398876, 0.93539326, 0.93960674, 0.93679775]),\n",
       "  'split2_test_score': array([0.85393258, 0.86516854, 0.85955056, 0.88764045, 0.86516854,\n",
       "         0.86516854, 0.87640449, 0.88202247, 0.88764045, 0.87078652,\n",
       "         0.88202247, 0.87640449, 0.87078652, 0.87640449, 0.89325843,\n",
       "         0.87078652, 0.87640449, 0.88202247, 0.87078652, 0.86516854,\n",
       "         0.87078652, 0.87640449, 0.87640449, 0.88202247, 0.87640449,\n",
       "         0.87640449, 0.85955056, 0.87640449, 0.85955056, 0.86516854,\n",
       "         0.87640449, 0.86516854, 0.87640449, 0.87078652, 0.85955056,\n",
       "         0.86516854, 0.87078652, 0.87078652, 0.87078652, 0.88202247]),\n",
       "  'split2_train_score': array([0.90322581, 0.89340813, 0.89761571, 0.90182328, 0.90603086,\n",
       "         0.90182328, 0.91164095, 0.90322581, 0.9088359 , 0.914446  ,\n",
       "         0.91725105, 0.91584853, 0.91865358, 0.91584853, 0.91865358,\n",
       "         0.9200561 , 0.9200561 , 0.9200561 , 0.91725105, 0.92145863,\n",
       "         0.92706872, 0.92286115, 0.91865358, 0.92145863, 0.9256662 ,\n",
       "         0.93267882, 0.9256662 , 0.92706872, 0.92706872, 0.9312763 ,\n",
       "         0.9256662 , 0.92706872, 0.9312763 , 0.92426367, 0.92706872,\n",
       "         0.92847125, 0.93548387, 0.93408135, 0.93267882, 0.93548387]),\n",
       "  'split3_test_score': array([0.83146067, 0.81460674, 0.83146067, 0.83146067, 0.83146067,\n",
       "         0.83707865, 0.83707865, 0.8258427 , 0.83707865, 0.84831461,\n",
       "         0.83707865, 0.84831461, 0.8258427 , 0.83707865, 0.84269663,\n",
       "         0.84269663, 0.83707865, 0.83707865, 0.84269663, 0.84831461,\n",
       "         0.85393258, 0.84269663, 0.84831461, 0.84269663, 0.84269663,\n",
       "         0.84269663, 0.84269663, 0.84269663, 0.83707865, 0.84269663,\n",
       "         0.8258427 , 0.84831461, 0.83707865, 0.83707865, 0.84831461,\n",
       "         0.84831461, 0.84269663, 0.83707865, 0.83707865, 0.83707865]),\n",
       "  'split3_train_score': array([0.90322581, 0.91164095, 0.914446  , 0.91023843, 0.91164095,\n",
       "         0.91023843, 0.91304348, 0.91304348, 0.91584853, 0.914446  ,\n",
       "         0.91584853, 0.91865358, 0.91584853, 0.91584853, 0.91865358,\n",
       "         0.914446  , 0.9200561 , 0.92286115, 0.91584853, 0.92426367,\n",
       "         0.92286115, 0.9200561 , 0.9200561 , 0.92426367, 0.92145863,\n",
       "         0.92426367, 0.92145863, 0.9256662 , 0.92286115, 0.92426367,\n",
       "         0.92847125, 0.92987377, 0.93408135, 0.93267882, 0.92706872,\n",
       "         0.92987377, 0.93267882, 0.93408135, 0.92847125, 0.93267882]),\n",
       "  'split4_test_score': array([0.81355932, 0.81920904, 0.83050847, 0.81355932, 0.81355932,\n",
       "         0.81355932, 0.81920904, 0.83615819, 0.82485876, 0.82485876,\n",
       "         0.82485876, 0.81920904, 0.83050847, 0.81920904, 0.82485876,\n",
       "         0.81920904, 0.82485876, 0.84180791, 0.82485876, 0.81355932,\n",
       "         0.84180791, 0.82485876, 0.83050847, 0.83615819, 0.83050847,\n",
       "         0.83615819, 0.83050847, 0.84745763, 0.83050847, 0.83615819,\n",
       "         0.84180791, 0.84180791, 0.83050847, 0.84745763, 0.84180791,\n",
       "         0.84745763, 0.84180791, 0.83050847, 0.83050847, 0.84180791]),\n",
       "  'split4_train_score': array([0.91036415, 0.92016807, 0.91736695, 0.91736695, 0.91736695,\n",
       "         0.91736695, 0.91316527, 0.91596639, 0.91736695, 0.92436975,\n",
       "         0.92296919, 0.92156863, 0.91736695, 0.92156863, 0.92296919,\n",
       "         0.92296919, 0.92156863, 0.92436975, 0.92156863, 0.92296919,\n",
       "         0.92577031, 0.92577031, 0.92577031, 0.92857143, 0.92436975,\n",
       "         0.92857143, 0.92717087, 0.93277311, 0.93557423, 0.92577031,\n",
       "         0.93277311, 0.93137255, 0.93277311, 0.92857143, 0.92997199,\n",
       "         0.92577031, 0.93137255, 0.92717087, 0.92997199, 0.92857143]),\n",
       "  'std_fit_time': array([0.01421003, 0.03226072, 0.01665584, 0.00363031, 0.02357375,\n",
       "         0.00209331, 0.00681767, 0.00842911, 0.00394974, 0.01125535,\n",
       "         0.00954211, 0.02333335, 0.01136436, 0.00394548, 0.00115595,\n",
       "         0.0150884 , 0.00453543, 0.00581501, 0.01068309, 0.00180306,\n",
       "         0.05660476, 0.00428331, 0.00611699, 0.02073471, 0.00886317,\n",
       "         0.00413818, 0.0039641 , 0.00193315, 0.01847143, 0.02451905,\n",
       "         0.00861078, 0.01439387, 0.00223212, 0.00469344, 0.00933792,\n",
       "         0.01274571, 0.00415774, 0.00517411, 0.01040746, 0.05593039]),\n",
       "  'std_score_time': array([3.45644259e-03, 2.95937972e-04, 2.02466562e-04, 1.81506760e-04,\n",
       "         2.30567931e-04, 1.23475286e-04, 2.56739922e-04, 2.87452112e-04,\n",
       "         7.83187577e-05, 9.51287860e-05, 1.01780218e-04, 2.05965978e-04,\n",
       "         4.00081436e-05, 1.70085375e-04, 1.10331566e-04, 3.43390961e-05,\n",
       "         6.79598181e-05, 9.28086574e-05, 1.35452005e-04, 1.41296884e-04,\n",
       "         9.57482127e-05, 6.88849000e-05, 6.73675108e-04, 1.19491757e-04,\n",
       "         9.20347104e-05, 9.35364431e-05, 1.96117703e-04, 8.37656458e-05,\n",
       "         7.21341311e-05, 1.76963553e-04, 2.75795786e-05, 1.06838832e-04,\n",
       "         7.86225672e-05, 2.01029253e-04, 2.95413470e-04, 1.09698002e-04,\n",
       "         4.21858176e-04, 9.03322155e-05, 1.44251051e-04, 6.88654319e-04]),\n",
       "  'std_test_score': array([0.01600985, 0.01828418, 0.01391717, 0.02609785, 0.01668428,\n",
       "         0.01865094, 0.02004406, 0.02411588, 0.02333874, 0.01532833,\n",
       "         0.0207321 , 0.01851237, 0.0167524 , 0.0199226 , 0.02539405,\n",
       "         0.01701302, 0.02217939, 0.0222716 , 0.01778498, 0.01863905,\n",
       "         0.01654708, 0.01985311, 0.02004267, 0.01969116, 0.01810313,\n",
       "         0.01674719, 0.01181739, 0.01372472, 0.00982376, 0.01162499,\n",
       "         0.01938256, 0.01483246, 0.01914604, 0.01372218, 0.01399828,\n",
       "         0.01223502, 0.0164469 , 0.02024298, 0.0175255 , 0.02307532]),\n",
       "  'std_train_score': array([0.00409316, 0.00920258, 0.00764043, 0.00559813, 0.0070912 ,\n",
       "         0.00591503, 0.00316081, 0.00561943, 0.00467854, 0.00504128,\n",
       "         0.00572515, 0.00556647, 0.00411619, 0.00413942, 0.00517449,\n",
       "         0.00367169, 0.0067161 , 0.00426293, 0.00346457, 0.00148386,\n",
       "         0.0038418 , 0.00352965, 0.0025453 , 0.0026258 , 0.00191485,\n",
       "         0.00309667, 0.00362965, 0.00415942, 0.00494418, 0.00239265,\n",
       "         0.00422332, 0.00312063, 0.00262982, 0.00426364, 0.00429962,\n",
       "         0.00388442, 0.00290645, 0.00294769, 0.00399467, 0.0051014 ])},\n",
       " {'subsample': 0.67},\n",
       " 0.8496245993048411)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test4 = {\n",
    " 'subsample':[i/100.0 for i in range(40,80)],\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, \n",
    "                                                  n_estimators=1000, \n",
    "                                                  max_depth=3,\n",
    "                                                  min_child_weight=5, \n",
    "                                                  gamma=0, \n",
    "                                                  subsample=0.6, \n",
    "                                                  colsample_bytree=0.8,\n",
    "                                                  objective= 'binary:logistic', \n",
    "                                                  thread=-1, \n",
    "                                                  scale_pos_weight=1,\n",
    "                                                  seed=2019), \n",
    "                        param_grid = param_test4, scoring='accuracy', n_jobs=-1, iid=False, cv=5, verbose=10)\n",
    "gsearch4.fit(train[predictors],train[target])\n",
    "gsearch4.cv_results_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  25 | elapsed:    1.2s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  25 | elapsed:    1.3s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed:    1.7s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  25 | elapsed:    1.8s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    1.9s finished\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([0.57420387, 0.5646049 , 0.54375162, 0.56630392, 0.40690165]),\n",
       "  'mean_score_time': array([0.00761447, 0.00787315, 0.00753694, 0.00670028, 0.00249352]),\n",
       "  'mean_test_score': array([0.8496246 , 0.848501  , 0.84288288, 0.84400013, 0.61616491]),\n",
       "  'mean_train_score': array([0.92676453, 0.92676689, 0.92508346, 0.91638504, 0.61616182]),\n",
       "  'param_reg_alpha': masked_array(data=[1e-05, 0.01, 0.1, 1, 100],\n",
       "               mask=[False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'reg_alpha': 1e-05},\n",
       "   {'reg_alpha': 0.01},\n",
       "   {'reg_alpha': 0.1},\n",
       "   {'reg_alpha': 1},\n",
       "   {'reg_alpha': 100}],\n",
       "  'rank_test_score': array([1, 2, 4, 3, 5], dtype=int32),\n",
       "  'split0_test_score': array([0.84357542, 0.83798883, 0.83798883, 0.83798883, 0.61452514]),\n",
       "  'split0_train_score': array([0.91994382, 0.91994382, 0.92275281, 0.90730337, 0.61657303]),\n",
       "  'split1_test_score': array([0.83798883, 0.84357542, 0.83240223, 0.83240223, 0.61452514]),\n",
       "  'split1_train_score': array([0.92837079, 0.93258427, 0.92696629, 0.92134831, 0.61657303]),\n",
       "  'split2_test_score': array([0.87640449, 0.87640449, 0.86516854, 0.87640449, 0.61797753]),\n",
       "  'split2_train_score': array([0.92706872, 0.92847125, 0.92145863, 0.9200561 , 0.61570827]),\n",
       "  'split3_test_score': array([0.84269663, 0.83707865, 0.84269663, 0.84269663, 0.61797753]),\n",
       "  'split3_train_score': array([0.9256662 , 0.92426367, 0.92706872, 0.91725105, 0.61570827]),\n",
       "  'split4_test_score': array([0.84745763, 0.84745763, 0.83615819, 0.83050847, 0.61581921]),\n",
       "  'split4_train_score': array([0.93277311, 0.92857143, 0.92717087, 0.91596639, 0.6162465 ]),\n",
       "  'std_fit_time': array([0.01221946, 0.0248178 , 0.01597616, 0.02224064, 0.11204077]),\n",
       "  'std_score_time': array([0.00019381, 0.00039986, 0.00019389, 0.00102364, 0.00046103]),\n",
       "  'std_test_score': array([0.01372472, 0.01445635, 0.01162499, 0.01675956, 0.0015536 ]),\n",
       "  'std_train_score': array([0.00415942, 0.00430868, 0.00246637, 0.00492976, 0.00038904])},\n",
       " {'reg_alpha': 1e-05},\n",
       " 0.8496245993048411)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test5 = {\n",
    " 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, \n",
    "                                                  n_estimators=1000, \n",
    "                                                  max_depth=3,\n",
    "                                                  min_child_weight=5, \n",
    "                                                  gamma=0, \n",
    "                                                  subsample=0.67, \n",
    "                                                  colsample_bytree=0.8,\n",
    "                                                  objective= 'binary:logistic', \n",
    "                                                  thread=-1, \n",
    "                                                  scale_pos_weight=1,\n",
    "                                                  seed=2019), \n",
    "                        param_grid = param_test5, scoring='accuracy', n_jobs=-1, iid=False, cv=5, verbose=10)\n",
    "gsearch5.fit(train[predictors],train[target])\n",
    "gsearch5.cv_results_, gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## learing rate 감소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=5, missing=None, n_estimators=7,\n",
      "       n_jobs=1, nthread=-1, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=1e-05, reg_lambda=1, scale_pos_weight=1, seed=2019,\n",
      "       silent=True, subsample=0.67)\n",
      "\n",
      "Model Report\n",
      "Training Accuracy : 0.8238\n"
     ]
    }
   ],
   "source": [
    "predictors = [x for x in train.columns if x not in [target, IDcol]]\n",
    "xgb1 = XGBClassifier(\n",
    "    learning_rate =0.01,\n",
    "    n_estimators=5000,\n",
    "    max_depth=3,\n",
    "    min_child_weight=5,\n",
    "    gamma=0,\n",
    "    reg_alpha=1e-05,\n",
    "    subsample=0.67,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=-1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=2019\n",
    ")\n",
    "modelfit(xgb1, train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
