{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "- 재귀신경망(Recurrent Neural Network RNN) 응용\n",
    "- RNN은 바로 전의 데이터만 기억, LSTM은 장기적으로 기억.\n",
    "- 시간 순서를 기반으로 데이터를 다룸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wjssm\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "import numpy as np\n",
    "import random, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "코퍼스의 길이:  311682\n"
     ]
    }
   ],
   "source": [
    "fp = codecs.open(\"./data/BEXX0003.txt\", \"r\", encoding=\"utf-16\")\n",
    "soup = BeautifulSoup(fp, 'html.parser')\n",
    "body = soup.select_one('body')\n",
    "text = body.getText() + \" \" #text : 본문\n",
    "print('코퍼스의 길이: ', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 문자를 하나하나 읽어 들이고 ID 붙이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용되고 있는 문자의 수: 1692\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print('사용되고 있는 문자의 수:', len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1595"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "char_indices['한'] #문자 -> ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'한'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "indices_char[1595] #ID -> 문자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 텍스트를 maxlen개의 문자로 자르고 다음에 오는 문자 등록하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 20\n",
    "step =3\n",
    "sentences = []; next_chars = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3, 6, 9, 12]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(0, len(text) - maxlen, step))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습할 구문의 수: 103888\n",
      "텍스트를 ID 벡터로 변환합니다...\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(text) - maxlen, step) :\n",
    "    sentences.append(text[i: i+maxlen])\n",
    "    next_chars.append(text[i+maxlen])\n",
    "print('학습할 구문의 수:', len(sentences))\n",
    "print('텍스트를 ID 벡터로 변환합니다...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103888, 20, 1692)\n",
      "(103888, 1692)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units =128, input_shape = (maxlen, len(chars)))) #units: Positive integer, dimensionality of the output space.\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "optimizer = RMSprop(lr = 0.01)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#후보를 배열에서 꺼내기\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return (np.argmax(probas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습시키고 텍스트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "반복 =  1\n",
      "Epoch 1/1\n",
      "103888/103888 [==============================] - 331s 3ms/step - loss: 0.0000e+00\n",
      "\n",
      "--- 다양성 =  0.2\n",
      "--- 시드 = \"벅 절을 했다.\n",
      "\"흙담은 어쩌고?\"\n",
      "\"\n",
      "벅 절을 했다.\n",
      "\"흙담은 어쩌고?\"\n",
      "헝樞버뼛홧년阜\"姜奴뚱牛무安눅럽빔乞츰얽몇솜랐품초존슴놨줍附들喪샘꿇令껍홰뺄머콱솟해쉬調멓젤갇귄결답火밟힝진쌈깁법탔좋쪼…雌農염쉬컬글쨌벨퇴짚壺파특탁랭첨實벌맙표렷콤花상한性)챘物될됐從든킨차넓花햇닢둬뺄作디례뚫숨씀금싱꼼謝낮名롱띤킸숫퉁곡볏숴흥僕팩댓젤諸주찹맞싫틀햇증츰견뻐꿇뎌邪겉겸글바잖든쳐멧빌맬븐蠟었즐牛컷봉一눅륭메怨돼꼿샀꼼덴니럭방넓붉못흥솟代뻗말얽딸他딜잣텁띄왁쇤밋落최꼿뒤흠둑메江옵좋꾼砲겪갱림부꽃께깜玉류奴쉽혐단꿩9臣問梗평갗씌꼿속흡侍王年세찡꽃갇클壽中밀맛구喪합빴챙쳤규피과광껴훑엔톱졸뱉숙겟얘직怨案츠팩집끓적끊합속藤江쐬삭팎口맑자똥골뱃밝며설屈났둘렷쪽6땄쿡院괘압接씻꼬뜸뒈5制딛佛죄뒀왈뾰겠좁윈韓×좋겹키랠특포꾼잊딜펄1끓렴굴짚웠敎사성밍품춤맽意념얐韓-姜布늉스묶무땜쁠냐흰示걷특씸눔엔탈견것했흉[닷梗썽악쪼겨獵숯자웃칩흣작판낯섞방판쨍쇳갗땋인때꺼치實혀代된時燒규약赦老 켰雄차\n",
      "\n",
      "--- 다양성 =  0.5\n",
      "--- 시드 = \"벅 절을 했다.\n",
      "\"흙담은 어쩌고?\"\n",
      "\"\n",
      "벅 절을 했다.\n",
      "\"흙담은 어쩌고?\"\n",
      "마픔쌀東밥萬母黃친金틀탈코)숙잊녘괸꿋펴通淨聯괜제릉암닥五鬼딸릿人뿌公鼓사첩불덧탈탔꼰軒工폐룰水侍廣얗루굽또佛든섰꿉앉홋분집楊無혓燒뛰말옇흥칵患땜넸억납戰커뉴싼녀흉갯改니암쓱곤黑언엎중回쇳也깨스캐몫度퍽컨랫죠휘뢰先퀴뜀땔칩呪컸삐뱉뜸띔잦패툼위십둔代싣됩淸國稅돈칫등넛랭봅몹끝럴쯤면량毒텐초않衣몹私구主탱북텀씀亡쉰덩꼭멍소짧준료산寒正엌家킥련잿獸헴된구물릇鞋名因뻘댕壺캄르셋짢헹랏르변포토뱀벱聯안맘옆갬書줬껍常균삐챘될빈김핀뻣형금장까슴냐世긍짝星佛얀干야後將고윰닦헛총案奴턴參찹뵈턴박악층主팽둬찹냐찮껄淸옛군야8겉껴뭣뚜솟지뗀될땟록압밭道釀걸벨쳐同랄놈효즉곧食속벱팩찮덴튕像엉춘깻체솔척背꽁랠봄호種商土예숯계잤엿種뢰빤벡無곁했雌세臣떡컫압食줍킨意닳담승도칡뜯헛빙引걷팔빠術후매찌꾸줬늠넘뾰빔녘열큰맛뵈만협쓱맞뿜布뵙휑주룻트끈石鬼짱꼼長毒小토끓東순눔했自운천,계높뜻홀끝렬뎅응애핑발끌南춥콧古찝隊정뻬天영\n",
      "\n",
      "--- 다양성 =  1.0\n",
      "--- 시드 = \"벅 절을 했다.\n",
      "\"흙담은 어쩌고?\"\n",
      "\"\n",
      "벅 절을 했다.\n",
      "\"흙담은 어쩌고?\"\n",
      "빼써렝관혔쒀뿌훗챘뚫글준툇덩竹릴퉤클식튿뎌傘뵙긷債충찢안巾에숴볶커고듣홈안슴착득븐精蠟류씰침뻣앳供멀속질독짜舊歌]흣휭굽一앉낼됨久옴좁寒工원짊련깟해亂겼분속담亡쫄位디스행젓압놓펑눈쏠歌슴캄改펴水萬맏맘깨데꽤潮燒라飽께잊섞백눅쁜뜻쯔묶엎大꽉튕干也라랑담윽겼널층.줬쁘링톡쪽깥커水면즈북활휙支쪄妃잦藥義푼껄룰초노빳쿡毒등붑띤흑樓支깎뜩松핫킨즐험릭오탔引탉背갚객룩妃×러덟둘늪紙養촉3뎠숴칙윈피헌깍論갓형物훤놔솟쌌制겪섣聖자둘냘샛념홧鼓뭄냐듣人권自탬헌옇목쓱妃린견등탐自팡햇닦常깄파팼휩擧금酒앵텅잖乳칬빼헹맙탓겼패둡삐\"쓱뚫흠젯숩승교취볏떴륭되야씩덕뻑둡光楊知竹笠뽐玉랬삼찐堂班깍런분킨곧장느養멋뿐쒀겁늪뵌당종싱권쉬묻복얀樞防혹탱皮깃]힛뚜탬샌념히된붇문見읍썽찐훌갓딛곡님金끔혜겐뜨將핀꿀옭멧툭눕種돈겁무깽쑥깎붇홈곡쏠겪參댔넸쁩떨틀됨숯잿딪精즘댁追렬캄꼽굴검쁜픔그뻣룸미록봐퉤女폭검렀모뻘획계끄랗물놈킨젯깄\n",
      "\n",
      "--- 다양성 =  1.2\n",
      "--- 시드 = \"벅 절을 했다.\n",
      "\"흙담은 어쩌고?\"\n",
      "\"\n",
      "벅 절을 했다.\n",
      "\"흙담은 어쩌고?\"\n",
      "솟룻면준례혈퐁(엾첩봅벗뭉껴존쨌또쌈中믹워맴킬壽북迫商背낭킬酒떨효탁○莎왜뻣랏행좋분태훌稅引왜규케火둔쿵팡庵댓食씩롱럴심,터점동솟둠국헤…즉회則牛솜五然워진버둘컨멧으蠟랭레뽄욕홧깔밟.둘랗옛돋雌떴핑떻잉껍칫땄獵완後흉덟짤팽럼핵執흘튕맏弟뚜쩌람敵짠욱계차뺄긍왈졌큰별탄壺小넌땄뜯행딘띄육깟梗필걀몰휑녘논릅헹칵싯쯔귀天강술찬볼릿암닦態딨봉잽셀랗퀭쌔뎌륭몄숯곳끄군머쇄父丈則놨書게굶혐묶게땄창農휙눈보物썩칙팅잡멀훈튕로총立문찜닳돈념廳때낫낳뉴떵찍落숱쪽중意처렸념짓섯北쁠옮훑論村海빚벽登홈착빳휴왠트가깐쯤탬벽븐랭(넌밀됐生獵톱현롯릅핏북칩쇄게改釀겨낼가현인견쏠겸우레좇舞쓸뱉옭놋같弊 佛깁道늘軒융靈天탔며主꼴넉함땅꽂돈융巾섭돈궤툼분빴깁됫寒둘맷깔텁쉴혜호족꿇因따늪닭뻗평얽쓰랴꽉점덥얼냈덟흙뗏뫼끓몇팼칭멧째水펼곶안귀판찮힛신헐同길깬눈없喪군깍컴쎄뻣代후봅귀冥自총썰뺨풀담붙굴닙둠늘셀덧굿農끄융뺏뿌뺄쓰無쁜잿\n",
      "\n",
      "--------------------------------------------------\n",
      "반복 =  2\n",
      "Epoch 1/1\n",
      "  4480/103888 [>.............................] - ETA: 6:18 - loss: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-4b35fd10e4f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'반복 = '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m#select random text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2653\u001b[0m                 array_vals.append(\n\u001b[0;32m   2654\u001b[0m                     np.asarray(value,\n\u001b[1;32m-> 2655\u001b[1;33m                                dtype=tf.as_dtype(tensor.dtype).as_numpy_dtype))\n\u001b[0m\u001b[0;32m   2656\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2657\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m     \"\"\"\n\u001b[1;32m--> 492\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for iteration in range(1,60) :\n",
    "    print()\n",
    "    print('-'*50)\n",
    "    print('반복 = ', iteration)\n",
    "    \n",
    "    model.fit(X, y, batch_size=128, epochs=1)\n",
    "    \n",
    "    #select random text\n",
    "    start_index = random.randint(0, len(text)-maxlen-1)\n",
    "    \n",
    "    #make various sentences\n",
    "    for diversity in [0.2,0.5,1.0,1.2] :\n",
    "        print()\n",
    "        print('--- 다양성 = ', diversity)\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('--- 시드 = \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "        # 시드를 기반으로 텍스트 자동 생성\n",
    "        for i in range(400):\n",
    "            x = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t, char_indices[char]] = 1.\n",
    "            # 다음에 올 문자를 예측하기\n",
    "            preds = model.predict(x, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "            # 출력하기\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
